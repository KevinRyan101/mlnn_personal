{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks image recognition - MultiLayer Perceptron\n",
    "Use both MLNN for the following problem.\n",
    "\n",
    "1. Add random noise (see below on `size parameter` on [`np.random.normal`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)) to the images in training and testing. **Make sure each image gets a different noise feature added to it. Inspect by printing out several images. Note - the `size` parameter should match the data. **\n",
    "2. Compare the `accuracy` of train and val after N epochs for MLNN with and without noise. \n",
    "3. Vary the amount of noise by changing the `scale` parameter in `np.random.normal` by a factor. Use `.1, .5, 1.0, 2.0, 4.0` for the `scale` and keep track of the `accuracy` for training and validation and plot these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `np.random.normal`\n",
    "\n",
    "## Parameters\n",
    "\n",
    "### loc\n",
    "\n",
    "Mean (“centre”) of the distribution.\n",
    "\n",
    "### scale\n",
    "\n",
    "Standard deviation (spread or “width”) of the distribution. Must be non-negative.\n",
    "\n",
    "### size\n",
    "\n",
    "Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. If size is None (default), a single value is returned if loc and scale are both scalars. Otherwise, np.broadcast(loc, scale).size samples are drawn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Layer Neural Network\n",
    "Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Use .1, .5, 1.0, 2.0, 4.0\n",
    "\n",
    "x_train_noise10 = x_train + np.random.normal(0, 255*.10, x_train.shape)\n",
    "x_test_noise10 = x_test + np.random.normal(0, 255*.10, x_test.shape)\n",
    "\n",
    "x_train_noise50 = x_train + np.random.normal(0, 255*.50, x_train.shape)\n",
    "x_test_noise50 = x_test + np.random.normal(0, 255*.50, x_test.shape)\n",
    "\n",
    "x_train_noise1 = x_train + np.random.normal(0, 255*1, x_train.shape)\n",
    "x_test_noise1 = x_test + np.random.normal(0, 255*1, x_test.shape)\n",
    "\n",
    "x_train_noise2 = x_train + np.random.normal(0, 255*2, x_train.shape)\n",
    "x_test_noise2 = x_test + np.random.normal(0, 255*2, x_test.shape)\n",
    "\n",
    "x_train_noise4 = x_train + np.random.normal(0, 255*4, x_train.shape)\n",
    "x_test_noise4 = x_test + np.random.normal(0, 255*4, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.2441 - accuracy: 0.9253 - val_loss: 0.1053 - val_accuracy: 0.9666\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1039 - accuracy: 0.9688 - val_loss: 0.0856 - val_accuracy: 0.9740\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0744 - accuracy: 0.9771 - val_loss: 0.0778 - val_accuracy: 0.9775\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0615 - accuracy: 0.9818 - val_loss: 0.0684 - val_accuracy: 0.9795\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0498 - accuracy: 0.9852 - val_loss: 0.0792 - val_accuracy: 0.9797\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 0.0799 - val_accuracy: 0.9806\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0384 - accuracy: 0.9885 - val_loss: 0.0837 - val_accuracy: 0.9811\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0319 - accuracy: 0.9906 - val_loss: 0.0943 - val_accuracy: 0.9812\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0315 - accuracy: 0.9906 - val_loss: 0.0881 - val_accuracy: 0.9812\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0271 - accuracy: 0.9923 - val_loss: 0.0901 - val_accuracy: 0.9833\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0274 - accuracy: 0.9924 - val_loss: 0.0869 - val_accuracy: 0.9829\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0231 - accuracy: 0.9935 - val_loss: 0.1126 - val_accuracy: 0.9818\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0255 - accuracy: 0.9933 - val_loss: 0.1098 - val_accuracy: 0.9816\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0210 - accuracy: 0.9939 - val_loss: 0.1128 - val_accuracy: 0.9830\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0229 - accuracy: 0.9938 - val_loss: 0.1139 - val_accuracy: 0.9816\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0206 - accuracy: 0.9947 - val_loss: 0.1132 - val_accuracy: 0.9837\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0189 - accuracy: 0.9946 - val_loss: 0.1263 - val_accuracy: 0.9843\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.1198 - val_accuracy: 0.9840\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0196 - accuracy: 0.9950 - val_loss: 0.1142 - val_accuracy: 0.9833\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.1307 - val_accuracy: 0.9829\n",
      "Test loss: 0.13065315783023834\n",
      "Test accuracy: 0.9829000234603882\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score_nn = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score_nn[0])\n",
    "print('Test accuracy:', score_nn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 3.8668 - accuracy: 0.1072 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3051 - accuracy: 0.1165 - val_loss: 2.3078 - val_accuracy: 0.1126\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2933 - accuracy: 0.1206 - val_loss: 2.3033 - val_accuracy: 0.1123\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2823 - accuracy: 0.1255 - val_loss: 2.3042 - val_accuracy: 0.1130\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.2740 - accuracy: 0.1287 - val_loss: 2.3033 - val_accuracy: 0.1134\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2692 - accuracy: 0.1314 - val_loss: 2.3021 - val_accuracy: 0.1132\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2706 - accuracy: 0.1325 - val_loss: 2.3016 - val_accuracy: 0.1137\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2660 - accuracy: 0.1342 - val_loss: 2.3051 - val_accuracy: 0.1133\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2633 - accuracy: 0.1357 - val_loss: 2.3048 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2620 - accuracy: 0.1371 - val_loss: 2.3045 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2607 - accuracy: 0.1388 - val_loss: 2.3043 - val_accuracy: 0.1138\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.2604 - accuracy: 0.1399 - val_loss: 2.3051 - val_accuracy: 0.1133\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2595 - accuracy: 0.1402 - val_loss: 2.3046 - val_accuracy: 0.1134\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2540 - accuracy: 0.1417 - val_loss: 2.3055 - val_accuracy: 0.1127\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2552 - accuracy: 0.1420 - val_loss: 2.3056 - val_accuracy: 0.1137\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2531 - accuracy: 0.1430 - val_loss: 2.3041 - val_accuracy: 0.1131\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2556 - accuracy: 0.1431 - val_loss: 2.3023 - val_accuracy: 0.1134\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2508 - accuracy: 0.1454 - val_loss: 2.3048 - val_accuracy: 0.1137\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.2498 - accuracy: 0.1439 - val_loss: 2.3028 - val_accuracy: 0.1133\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2507 - accuracy: 0.1447 - val_loss: 2.3046 - val_accuracy: 0.1135\n",
      "Test loss: 2.3046178817749023\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise10, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise10, y_test))\n",
    "score_nn10 = model.evaluate(x_test_noise10, y_test, verbose=0)\n",
    "print('Test loss:', score_nn10[0])\n",
    "print('Test accuracy:', score_nn10[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 12.1866 - accuracy: 0.1081 - val_loss: 2.3023 - val_accuracy: 0.1137\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3130 - accuracy: 0.1136 - val_loss: 2.3017 - val_accuracy: 0.1136\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3124 - accuracy: 0.1142 - val_loss: 2.3025 - val_accuracy: 0.1135\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3099 - accuracy: 0.1148 - val_loss: 2.3017 - val_accuracy: 0.1135\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3065 - accuracy: 0.1152 - val_loss: 2.3027 - val_accuracy: 0.1136\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3090 - accuracy: 0.1157 - val_loss: 2.3019 - val_accuracy: 0.1135\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3041 - accuracy: 0.1160 - val_loss: 2.3014 - val_accuracy: 0.1134\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3050 - accuracy: 0.1159 - val_loss: 2.3015 - val_accuracy: 0.1134\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1163 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2996 - accuracy: 0.1168 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2991 - accuracy: 0.1164 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2967 - accuracy: 0.1168 - val_loss: 2.3010 - val_accuracy: 0.1137\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3010 - accuracy: 0.1168 - val_loss: 2.3013 - val_accuracy: 0.1136\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2986 - accuracy: 0.1171 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.2990 - accuracy: 0.1171 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2960 - accuracy: 0.1176 - val_loss: 2.3016 - val_accuracy: 0.1136\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.2936 - accuracy: 0.1177 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2953 - accuracy: 0.1176 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2992 - accuracy: 0.1176 - val_loss: 2.3034 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2955 - accuracy: 0.1176 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
      "Test loss: 2.3009188175201416\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise50, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise50, y_test))\n",
    "score_nn50 = model.evaluate(x_test_noise50, y_test, verbose=0)\n",
    "print('Test loss:', score_nn50[0])\n",
    "print('Test accuracy:', score_nn50[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_48 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 21.6476 - accuracy: 0.1103 - val_loss: 2.3032 - val_accuracy: 0.1134\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3326 - accuracy: 0.1131 - val_loss: 2.3010 - val_accuracy: 0.1134\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 2.3199 - accuracy: 0.1137 - val_loss: 2.3013 - val_accuracy: 0.1133\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 4s 7ms/step - loss: 2.3186 - accuracy: 0.1141 - val_loss: 2.3024 - val_accuracy: 0.1134\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3162 - accuracy: 0.1145 - val_loss: 2.3016 - val_accuracy: 0.1135\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3127 - accuracy: 0.1147 - val_loss: 2.3012 - val_accuracy: 0.1134\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3106 - accuracy: 0.1148 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 2.3088 - accuracy: 0.1148 - val_loss: 2.3015 - val_accuracy: 0.1135\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3051 - accuracy: 0.1151 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3043 - accuracy: 0.1151 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3007 - accuracy: 0.1153 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3068 - accuracy: 0.1154 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3032 - accuracy: 0.1157 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3063 - accuracy: 0.1157 - val_loss: 2.3023 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3037 - accuracy: 0.1156 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3031 - accuracy: 0.1156 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3043 - accuracy: 0.1159 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3053 - accuracy: 0.1158 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.2993 - accuracy: 0.1158 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3016 - accuracy: 0.1158 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.300942897796631\n",
      "Test accuracy: 0.1136000007390976\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise1, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise50, y_test))\n",
    "score_nn1 = model.evaluate(x_test_noise1, y_test, verbose=0)\n",
    "print('Test loss:', score_nn1[0])\n",
    "print('Test accuracy:', score_nn1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_51 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 36.6212 - accuracy: 0.1083 - val_loss: 2.3022 - val_accuracy: 0.1135\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3491 - accuracy: 0.1128 - val_loss: 2.3014 - val_accuracy: 0.1133\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3278 - accuracy: 0.1129 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3256 - accuracy: 0.1132 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3203 - accuracy: 0.1135 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3225 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3155 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3112 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3114 - accuracy: 0.1137 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3112 - accuracy: 0.1138 - val_loss: 2.3012 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3111 - accuracy: 0.1138 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3155 - accuracy: 0.1140 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3085 - accuracy: 0.1140 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3061 - accuracy: 0.1142 - val_loss: 2.3009 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3065 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3008 - accuracy: 0.1142 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3048 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3053 - accuracy: 0.1145 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3013 - accuracy: 0.1144 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010334968566895\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise2, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise2, y_test))\n",
    "score_nn2 = model.evaluate(x_test_noise2, y_test, verbose=0)\n",
    "print('Test loss:', score_nn2[0])\n",
    "print('Test accuracy:', score_nn2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 76.5918 - accuracy: 0.1070 - val_loss: 2.3032 - val_accuracy: 0.1135\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3895 - accuracy: 0.1125 - val_loss: 2.3014 - val_accuracy: 0.1135\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3526 - accuracy: 0.1127 - val_loss: 2.3043 - val_accuracy: 0.1134\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3438 - accuracy: 0.1130 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 2.3303 - accuracy: 0.1129 - val_loss: 2.3030 - val_accuracy: 0.1135\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 2.3284 - accuracy: 0.1129 - val_loss: 2.3014 - val_accuracy: 0.1134\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3214 - accuracy: 0.1131 - val_loss: 2.3023 - val_accuracy: 0.1134\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3215 - accuracy: 0.1132 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3171 - accuracy: 0.1133 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3147 - accuracy: 0.1134 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3187 - accuracy: 0.1132 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3192 - accuracy: 0.1133 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3122 - accuracy: 0.1132 - val_loss: 2.3011 - val_accuracy: 0.1135\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3130 - accuracy: 0.1133 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3113 - accuracy: 0.1135 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3057 - accuracy: 0.1135 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 2.3083 - accuracy: 0.1135 - val_loss: 2.3013 - val_accuracy: 0.1135\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3125 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3084 - accuracy: 0.1136 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 2.3079 - accuracy: 0.1135 - val_loss: 2.3010 - val_accuracy: 0.1135\n",
      "Test loss: 2.3010404109954834\n",
      "Test accuracy: 0.11349999904632568\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train_noise4, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test_noise4, y_test))\n",
    "score_nn4 = model.evaluate(x_test_noise4, y_test, verbose=0)\n",
    "print('Test loss:', score_nn4[0])\n",
    "print('Test accuracy:', score_nn4[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe36dc80a00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_losses = np.array([score_nn[0], score_nn10[0], score_nn50[0], score_nn1[0], score_nn2[0], score_nn4[0]])\n",
    "plt.plot(nn_losses, label='NN Losses', color='b')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13065316, 2.30461788, 2.30091882, 2.3009429 , 2.3010335 ,\n",
       "       2.30104041])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe3193e4df0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nn_accur = np.array([score_nn[1], score_nn10[1], score_nn50[1], score_nn1[1], score_nn2[1], score_nn4[1]])\n",
    "plt.plot(nn_accur, label='NN Accuracy', color='b')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98290002, 0.1135    , 0.1135    , 0.1136    , 0.1135    ,\n",
       "       0.1135    ])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As seen in the visualizations of both loss and accuracy above, adding noise (.10 to .50 to 1 to 2 to 4) greatly increases loss and decreases accuracy- even at a low level. It is interesting though that once noise wrecks the result, adding more noise does not further degrade accuracy or increase loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
